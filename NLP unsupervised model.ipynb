{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP  Project \"Text Summarizer for Kazakh news in russian\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "#--------#\n",
    "import natasha\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title of the article\n",
    "title = \"Пропал экс-главврач омской больницы, где лежал Навальный\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input text - to summarize'\n",
    "text = \"Министр здравоохранения Омской области Александр Мураховский пропал без вести в лесу. Ранее он являлся главврачом больницы, куда летом 2020 года был доставлен российский оппозиционер Алексей Навальный. Как пишет РИА Новости, в полиции сообщили, что Мураховский 7 мая уехал на квадроцикле с охотбазы (в 270-ми километрах от Омска) в лес и пропал. Официальную пропажу министра подтвердили накануне вечером. Сообщается, что квадроцикл Мураховского нашли в 6 километрах от базы. В поисках участвуют волонтеры из отряда 'Лиза Алерт', 'Доброспас', личный состав местного пункта полиции, сотрудники Росгвардии, а также местные жители. Задействован вертолет и беспилотники. В ГУМЧС по Омской области добавили, что на поиски направлено 10 спасателей на двух личных автомобилях. Также в пресс-службе УМВД региона опровергли ранее появившуюся в Сети информацию о том, что чиновника нашли. Согласно последним данным, поиски ночью прекратились из-за плохой видимости и погодных условий, утром их возобновили. По информации РБК, Александр Мураховский возглавил региональный Минздрав в ноябре 2020 года. До этого он занимал пост главного врача больницы скорой помощи № 1, куда в августе прошлого года доставили оппозиционера Алексея Навального.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "пропадать экс - главврач омский больница ,  лежать навальный \n",
      "\n",
      "министр здравоохранение омский область александр мураховский пропадать весть лес . ранее являться главврач больница ,  лето 2020 год доставлять российский оппозиционер алексей навальный . писать риа новость ,  полиция сообщать ,  мураховский 7 май уезжать квадроцикл охотбаза  ( 270 - ми километр омск )  лес пропадать . официальный пропажа министр подтверждать накануне вечер . сообщаться ,  квадроцикл мураховский находить 6 километр база . поиск участвовать волонтер отряд  ' лиза алерт ', ' доброспас ',  личный состав местный пункт полиция ,  сотрудник росгвардия ,  также местный житель . задействовать вертолет беспилотник . гумчс омский область добавлять ,  поиск направлять 10 спасатель личный автомобиль . также пресс-служба умвд регион опровергать ранее появляться сеть информация ,  чиновник находить . согласно последний данные ,  поиск ночь прекращаться из-за плохой видимость погодный условие ,  утро возобновлять . информация рбк ,  александр мураховский возглавлять региональный минздрав ноябрь 2020 год . это занимать пост главный врач больница скорый помощь № 1 ,  август прошлый год доставлять оппозиционер алексей навальный . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create lemmatizer and stopwords list\n",
    "mystem = Mystem() \n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "#Preprocess function\n",
    "def preprocess_text(text):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \"]\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text\n",
    "\n",
    "#Preprocess text (sentence with lemmatized words)\n",
    "preproc_title=preprocess_text(title)    \n",
    "preproc_text=preprocess_text(text)\n",
    "\n",
    "print(preproc_title)\n",
    "print(preproc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the text\n",
    "words = word_tokenize(preproc_text)\n",
    "words = [word for word in words if word.strip() not in punctuation]\n",
    "\n",
    "# Creating a frequency table to keep the\n",
    "# score of each word\n",
    "\n",
    "freqTable = dict()\n",
    "for word in words:\n",
    "    word = word.lower()\n",
    "    if word in freqTable:\n",
    "        freqTable[word] += 1\n",
    "    else:\n",
    "        freqTable[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['пропадать', 'экс', 'главврач', 'омский', 'больница', 'лежать', 'навальный']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing the title\n",
    "words_title=word_tokenize(preproc_title)\n",
    "words_title=[word for word in words_title if word.strip() not in punctuation]\n",
    "words_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'министр': 2,\n",
       " 'здравоохранение': 1,\n",
       " 'омский': 2,\n",
       " 'область': 2,\n",
       " 'александр': 2,\n",
       " 'мураховский': 4,\n",
       " 'пропадать': 2,\n",
       " 'весть': 1,\n",
       " 'лес': 2,\n",
       " 'ранее': 2,\n",
       " 'являться': 1,\n",
       " 'главврач': 1,\n",
       " 'больница': 2,\n",
       " 'лето': 1,\n",
       " '2020': 2,\n",
       " 'год': 3,\n",
       " 'доставлять': 2,\n",
       " 'российский': 1,\n",
       " 'оппозиционер': 2,\n",
       " 'алексей': 2,\n",
       " 'навальный': 2,\n",
       " 'писать': 1,\n",
       " 'риа': 1,\n",
       " 'новость': 1,\n",
       " 'полиция': 2,\n",
       " 'сообщать': 1,\n",
       " '7': 1,\n",
       " 'май': 1,\n",
       " 'уезжать': 1,\n",
       " 'квадроцикл': 2,\n",
       " 'охотбаза': 1,\n",
       " '270': 1,\n",
       " 'ми': 1,\n",
       " 'километр': 2,\n",
       " 'омск': 1,\n",
       " 'официальный': 1,\n",
       " 'пропажа': 1,\n",
       " 'подтверждать': 1,\n",
       " 'накануне': 1,\n",
       " 'вечер': 1,\n",
       " 'сообщаться': 1,\n",
       " 'находить': 2,\n",
       " '6': 1,\n",
       " 'база': 1,\n",
       " 'поиск': 3,\n",
       " 'участвовать': 1,\n",
       " 'волонтер': 1,\n",
       " 'отряд': 1,\n",
       " 'лиза': 1,\n",
       " 'алерт': 1,\n",
       " 'доброспас': 1,\n",
       " 'личный': 2,\n",
       " 'состав': 1,\n",
       " 'местный': 2,\n",
       " 'пункт': 1,\n",
       " 'сотрудник': 1,\n",
       " 'росгвардия': 1,\n",
       " 'также': 2,\n",
       " 'житель': 1,\n",
       " 'задействовать': 1,\n",
       " 'вертолет': 1,\n",
       " 'беспилотник': 1,\n",
       " 'гумчс': 1,\n",
       " 'добавлять': 1,\n",
       " 'направлять': 1,\n",
       " '10': 1,\n",
       " 'спасатель': 1,\n",
       " 'автомобиль': 1,\n",
       " 'пресс-служба': 1,\n",
       " 'умвд': 1,\n",
       " 'регион': 1,\n",
       " 'опровергать': 1,\n",
       " 'появляться': 1,\n",
       " 'сеть': 1,\n",
       " 'информация': 2,\n",
       " 'чиновник': 1,\n",
       " 'согласно': 1,\n",
       " 'последний': 1,\n",
       " 'данные': 1,\n",
       " 'ночь': 1,\n",
       " 'прекращаться': 1,\n",
       " 'из-за': 1,\n",
       " 'плохой': 1,\n",
       " 'видимость': 1,\n",
       " 'погодный': 1,\n",
       " 'условие': 1,\n",
       " 'утро': 1,\n",
       " 'возобновлять': 1,\n",
       " 'рбк': 1,\n",
       " 'возглавлять': 1,\n",
       " 'региональный': 1,\n",
       " 'минздрав': 1,\n",
       " 'ноябрь': 1,\n",
       " 'это': 1,\n",
       " 'занимать': 1,\n",
       " 'пост': 1,\n",
       " 'главный': 1,\n",
       " 'врач': 1,\n",
       " 'скорый': 1,\n",
       " 'помощь': 1,\n",
       " '№': 1,\n",
       " '1': 1,\n",
       " 'август': 1,\n",
       " 'прошлый': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary to keep the score of each sentence\n",
    "\n",
    "# 1st variant:  Summing the frequency of each word in the sentence\n",
    "sentences = sent_tokenize(preproc_text)\n",
    "sentenceValue = dict()\n",
    "\n",
    "for sentence in sentences:\n",
    "    for word, freq in freqTable.items():\n",
    "        if word in sentence.lower():\n",
    "            if sentence in sentenceValue:\n",
    "                sentenceValue[sentence] += freq/len(words)\n",
    "            else:\n",
    "                sentenceValue[sentence] = freq/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'министр здравоохранение омский область александр мураховский пропадать весть лес .': 0.1515151515151515,\n",
       " 'ранее являться главврач больница ,  лето 2020 год доставлять российский оппозиционер алексей навальный .': 0.16666666666666663,\n",
       " 'писать риа новость ,  полиция сообщать ,  мураховский 7 май уезжать квадроцикл охотбаза  ( 270 - ми километр омск )  лес пропадать .': 0.1969696969696969,\n",
       " 'официальный пропажа министр подтверждать накануне вечер .': 0.06060606060606061,\n",
       " 'сообщаться ,  квадроцикл мураховский находить 6 километр база .': 0.10606060606060605,\n",
       " \"поиск участвовать волонтер отряд  ' лиза алерт ', ' доброспас ',  личный состав местный пункт полиция ,  сотрудник росгвардия ,  также местный житель .\": 0.16666666666666663,\n",
       " 'задействовать вертолет беспилотник .': 0.022727272727272728,\n",
       " 'гумчс омский область добавлять ,  поиск направлять 10 спасатель личный автомобиль .': 0.12878787878787876,\n",
       " 'также пресс-служба умвд регион опровергать ранее появляться сеть информация ,  чиновник находить .': 0.12121212121212119,\n",
       " 'согласно последний данные ,  поиск ночь прекращаться из-за плохой видимость погодный условие ,  утро возобновлять .': 0.1363636363636363,\n",
       " 'информация рбк ,  александр мураховский возглавлять региональный минздрав ноябрь 2020 год .': 0.1515151515151515,\n",
       " 'это занимать пост главный врач больница скорый помощь № 1 ,  август прошлый год доставлять оппозиционер алексей навальный .': 0.18181818181818174}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['пропадать', 'экс', 'главврач', 'омский', 'больница', 'лежать', 'навальный']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(preproc_text)\n",
    "sentenceValue_2 = dict()\n",
    "for sentence in sentences:\n",
    "    for word in words_title:\n",
    "        if word in sentence:\n",
    "            if sentence in sentenceValue_2:\n",
    "                sentenceValue_2[sentence] += 1\n",
    "            else:\n",
    "                sentenceValue_2[sentence] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'министр здравоохранение омский область александр мураховский пропадать весть лес .': 2, 'ранее являться главврач больница ,  лето 2020 год доставлять российский оппозиционер алексей навальный .': 3, 'писать риа новость ,  полиция сообщать ,  мураховский 7 май уезжать квадроцикл охотбаза  ( 270 - ми километр омск )  лес пропадать .': 1, 'гумчс омский область добавлять ,  поиск направлять 10 спасатель личный автомобиль .': 1, 'это занимать пост главный врач больница скорый помощь № 1 ,  август прошлый год доставлять оппозиционер алексей навальный .': 2}\n"
     ]
    }
   ],
   "source": [
    "print(sentenceValue_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proper names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:01, 64.1kB/s]                    \n",
      "2021-06-10 09:33:18 INFO: Downloading default packages for language: ru (Russian)...\n",
      "2021-06-10 09:33:20 INFO: File exists: C:\\Users\\HP\\stanza_resources\\ru\\default.zip.\n",
      "2021-06-10 09:33:24 INFO: Finished downloading models and saved to C:\\Users\\HP\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('ru')\n",
    "def stanza_nlp_ru(text):\n",
    "    nlp = stanza.Pipeline(lang='ru', processors='tokenize,ner')\n",
    "    doc = nlp(text)\n",
    "    names = [ent.text for sent in doc.sentences for ent in sent.ents]\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-10 09:33:24 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "| ner       | wikiner   |\n",
      "=========================\n",
      "\n",
      "2021-06-10 09:33:24 INFO: Use device: cpu\n",
      "2021-06-10 09:33:24 INFO: Loading: tokenize\n",
      "2021-06-10 09:33:24 INFO: Loading: ner\n",
      "2021-06-10 09:33:26 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "names = stanza_nlp_ru(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['омский область ', 'александр мураховский ', 'алексей навальный ', 'риа новость ', 'омск ', \"' лиза алерт '\", \"' доброспас '\", 'росгвардия ', 'гумчс ', 'умвд регион ', 'сеть ', 'рбк ', 'региональный минздрав ']\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(preproc_text)\n",
    "sentenceValue_3 = dict()\n",
    "names_=[]\n",
    "names_uniq=[]\n",
    "all_names=\"\"\n",
    "for i in range(len(names)):\n",
    "    prep_name = preprocess_text(names[i])\n",
    "    prep_name = prep_name.replace(\"  \\n\", \"\")\n",
    "    prep_name = prep_name.replace(\"\\n\", \"\")\n",
    "    names_.append(prep_name)\n",
    "    if names_[i] not in all_names:\n",
    "        names_uniq.append(names_[i])\n",
    "    all_names = \" \".join(names_)\n",
    "print(names_uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    for name in names_uniq:\n",
    "        if name in sentence:\n",
    "            if sentence in sentenceValue_3:\n",
    "                sentenceValue_3[sentence] += 1\n",
    "            else:\n",
    "                sentenceValue_3[sentence] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'министр здравоохранение омский область александр мураховский пропадать весть лес .': 2,\n",
       " 'ранее являться главврач больница ,  лето 2020 год доставлять российский оппозиционер алексей навальный .': 1,\n",
       " 'писать риа новость ,  полиция сообщать ,  мураховский 7 май уезжать квадроцикл охотбаза  ( 270 - ми километр омск )  лес пропадать .': 2,\n",
       " \"поиск участвовать волонтер отряд  ' лиза алерт ', ' доброспас ',  личный состав местный пункт полиция ,  сотрудник росгвардия ,  также местный житель .\": 3,\n",
       " 'гумчс омский область добавлять ,  поиск направлять 10 спасатель личный автомобиль .': 2,\n",
       " 'также пресс-служба умвд регион опровергать ранее появляться сеть информация ,  чиновник находить .': 2,\n",
       " 'информация рбк ,  александр мураховский возглавлять региональный минздрав ноябрь 2020 год .': 3,\n",
       " 'это занимать пост главный врач больница скорый помощь № 1 ,  август прошлый год доставлять оппозиционер алексей навальный .': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceValue_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-10 09:33:55 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "| ner       | wikiner   |\n",
      "=========================\n",
      "\n",
      "2021-06-10 09:33:55 INFO: Use device: cpu\n",
      "2021-06-10 09:33:55 INFO: Loading: tokenize\n",
      "2021-06-10 09:33:55 INFO: Loading: ner\n",
      "2021-06-10 09:33:56 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Министр здравоохранения Омской области Александр Мураховский пропал без вести в лесу. Ранее он являлся главврачом больницы, куда летом 2020 года был доставлен российский оппозиционер Алексей Навальный.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "import operator\n",
    "\n",
    "#Preprocess function\n",
    "def preprocess_text(text):\n",
    "    #Create lemmatizer and stopwords list\n",
    "    mystem = Mystem() \n",
    "    russian_stopwords = stopwords.words(\"russian\")\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token not in russian_stopwords\\\n",
    "              and token != \" \"]\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text\n",
    "\n",
    "#Preprocess text (sentence with lemmatized words)\n",
    "preproc_title=preprocess_text(title)    \n",
    "preproc_text=preprocess_text(text)\n",
    "\n",
    "\n",
    "def stanza_nlp_ru(text):\n",
    "    nlp = stanza.Pipeline(lang='ru', processors='tokenize,ner')\n",
    "    doc = nlp(text)\n",
    "    names = [ent.text for sent in doc.sentences for ent in sent.ents]\n",
    "    return names\n",
    "\n",
    "names = stanza_nlp_ru(text)\n",
    "\n",
    "def unsupervised_summarization(preproc_text, preproc_title, names):\n",
    "\n",
    "    sentences = sent_tokenize(preproc_text)\n",
    "    sentenceValue = dict()\n",
    "\n",
    "\n",
    "    # Tokenizing the text\n",
    "    words = word_tokenize(preproc_text)\n",
    "    words = [word for word in words if word.strip() not in punctuation]\n",
    "\n",
    "    # Creating a frequency table to keep the\n",
    "    # score of each word\n",
    "\n",
    "    freqTable = dict()\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word in freqTable:\n",
    "            freqTable[word] += 1\n",
    "        else:\n",
    "            freqTable[word] = 1\n",
    "\n",
    "    # Tokenizing the title\n",
    "    words_title=word_tokenize(preproc_title)\n",
    "    words_title=[word for word in words_title if word.strip() not in punctuation]\n",
    "\n",
    "\n",
    "    names_=[]\n",
    "    names_uniq=[]\n",
    "    all_names=\"\"\n",
    "    for i in range(len(names)):\n",
    "        prep_name = preprocess_text(names[i])\n",
    "        prep_name = prep_name.replace(\"  \\n\", \"\")\n",
    "        prep_name = prep_name.replace(\"\\n\", \"\")\n",
    "        names_.append(prep_name)\n",
    "        if names_[i] not in all_names:\n",
    "            names_uniq.append(names_[i])\n",
    "        all_names = \" \".join(names_)\n",
    "\n",
    "\n",
    "    #ranking\n",
    "    for sentence in sentences:\n",
    "        for word, freq in freqTable.items():\n",
    "            if word in sentence.lower():\n",
    "                if sentence in sentenceValue:\n",
    "                    sentenceValue[sentence] += freq/len(words)\n",
    "                else:\n",
    "                    sentenceValue[sentence] = freq/len(words)\n",
    "        for title_w in words_title:\n",
    "            if title_w in sentence:\n",
    "                sentenceValue[sentence] += 1\n",
    "        for name in names_uniq:\n",
    "            if name in sentence:\n",
    "                sentenceValue[sentence] += 0.5\n",
    "\n",
    "    #summaring\n",
    "    sentences_old = sent_tokenize(text)\n",
    "    summary_len=len(sentences)/5\n",
    "\n",
    "    sorted_sentenceValue = sorted(sentenceValue.items(), key=operator.itemgetter(1))\n",
    "    sorted_sentenceValue.reverse()\n",
    "    summary_sen = dict(sorted_sentenceValue[:int(summary_len)])\n",
    "\n",
    "    summary = ''\n",
    "    for i in range(len(sentences)):\n",
    "        if sentences[i] in summary_sen:\n",
    "            summary += \" \" + sentences_old[i]\n",
    "    \n",
    "    return summary\n",
    "\n",
    "unsupervised_summarization(preproc_text, preproc_title, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'nlp.txt'\n",
    "parser = PlaintextParser.from_file(file, Tokenizer('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Министр здравоохранения Омской области Александр Мураховский пропал без вести в лесу.\n",
      "Сообщается, что квадроцикл Мураховского нашли в 6 километрах от базы.\n"
     ]
    }
   ],
   "source": [
    "#Lex rank - graphical based text summarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer \n",
    "summarizer = LexRankSummarizer()\n",
    "#Summarize the document with 2 sentences\n",
    "summary = summarizer(parser.document, 2) \n",
    "for sentence in summary:\n",
    " print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как пишет РИА Новости, в полиции сообщили, что Мураховский 7 мая уехал на квадроцикле с охотбазы (в 270-ми километрах от Омска) в лес и пропал.\n",
      "В ГУМЧС по Омской области добавили, что на поиски направлено 10 спасателей на двух личных автомобилях.\n"
     ]
    }
   ],
   "source": [
    "#Luhn - scores sentences based on frequency of the most important words\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "summarizer_1 = LuhnSummarizer()\n",
    "summary_1 =summarizer_1(parser.document,2)\n",
    "for sentence in summary_1:\n",
    " print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В поисках участвуют волонтеры из отряда 'Лиза Алерт', 'Доброспас', личный состав местного пункта полиции, сотрудники Росгвардии, а также местные жители.\n",
      "До этого он занимал пост главного врача больницы скорой помощи № 1, куда в августе прошлого года доставили оппозиционера Алексея Навального.\n"
     ]
    }
   ],
   "source": [
    "#LSA - Latent semantic analysis(combines term frequency techniques with singular value decomposition to summarize texts)\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "summarizer_2 = LsaSummarizer()\n",
    "summary_2 =summarizer_2(parser.document,2)\n",
    "for sentence in summary_2:\n",
    " print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как пишет РИА Новости, в полиции сообщили, что Мураховский 7 мая уехал на квадроцикле с охотбазы (в 270-ми километрах от Омска) в лес и пропал.\n",
      "Также в пресс-службе УМВД региона опровергли ранее появившуюся в Сети информацию о том, что чиновника нашли.\n"
     ]
    }
   ],
   "source": [
    "#Text Rank - a graph-based summarization technique with keyword extractions in from document\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "summarizer_3 = TextRankSummarizer()\n",
    "summary_3 =summarizer_3(parser.document,2)\n",
    "for sentence in summary_3:\n",
    " print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'f': 0.7750102032807114, 'p': 0.7452346041055719, 'r': 0.812442396313364}, 'rouge-2': {'f': 0.7393939344280938, 'p': 0.7108527131782946, 'r': 0.7754901960784314}, 'rouge-l': {'f': 0.8052197752345733, 'p': 0.7821428571428571, 'r': 0.8321428571428571}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from rouge import Rouge\n",
    "\n",
    "# Load some sentences\n",
    "with open('data.json') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "hyps, refs = map(list, zip(*[[d['hyp'], d['ref']] for d in data]))\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(hyps, refs)\n",
    "# or\n",
    "scores = rouge.get_scores(hyps, refs, avg=True)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
